# Introduction

## Motivations

Since antiquity the idea of building a thinking machine has always been in the minds of philosophers, artists, sciencemen, kings and commoners alike, filling us with wonder, terror and contemplation. A human creation capable of human feats, would turn us, at least in an allegorical sense, into gods.

Talk about why automata are a good benchmark.

* Easy to program
* Model complex systems
* Are models of universal computation

## Problem Statement

In this thesis, we consider the advantages of using Cellular Automata as underlying environments for RL tasks. To fully incorporate a CA into the RL framework a Markov Decision Process (MDP) should be defined. So we need to be able to find appropiate sets of _Actions_ ($\mathcal{A}$), _States_ ($\mathcal{S}$) and _Rewards_ ($\mathcal{R}$), also specify an "Agent" that interacts with the CA and explicitly or implicitly define the transitions of the MDP $p(s',r|s,a): \mathcal{S} \times \mathcal{R} \times \mathcal{S} \times \mathcal{A} \rightarrow [0,1]$.

Thus our first challange is engineering a RL task that succesfully integrates the Forest Fire CA with the semantics of an "Agent" or "Helicopter" flying over the forest trying to extinguish the wild fire.

The optimaztion problem that we want to solve is: Minimize the 

To Do: Describe the RL task and state the optimization problem. 

## Objectives

### Main Objectives

+ Propose a novel environment for Reinforcement Learning tasks, based on Cellular Automata, that could be used as an alternative benchmark instead of Atari games.
+ Characterize the environment by solving it by state of the art methods.

### Specific Objectives

+ Select a Cellular Automaton model for the environment, in this case the Forest Fire Cellular Automaton.
+ Design a RL task incorporating the CA dynamics.
+ Implementation of the RL environment, following the Open AI gym API.
+ Apply DQN to solve the proposed task.
