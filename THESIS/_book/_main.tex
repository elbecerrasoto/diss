% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Cellular Automata Control with Deep Reinforcement Learning},
  pdfauthor={Emanuel Becerra Soto},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{dsfont}
\usepackage{amsmath}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{cslreferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}

\title{Cellular Automata Control with Deep Reinforcement Learning}
\author{Emanuel Becerra Soto}
\date{2020-06-11}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{cellular-automata-control-with-deep-reinforcement-learning}{%
\chapter{Cellular Automata Control with Deep Reinforcement Learning}\label{cellular-automata-control-with-deep-reinforcement-learning}}

\hypertarget{abstract}{%
\section{Abstract}\label{abstract}}

\hypertarget{acknowledgments}{%
\section{Acknowledgments}\label{acknowledgments}}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{motivations}{%
\section{Motivations}\label{motivations}}

Since antiquity the idea of building a thinking machine has always been in the minds of philosophers, artists, sciencemen, kings and commoners alike, filling us with wonder, terror and contemplation. A human creation capable of human feats, would turn us, at least in an allegorical sense, into gods.

\hypertarget{objectives}{%
\section{Objectives}\label{objectives}}

\hypertarget{main-objectives}{%
\subsection{Main Objectives}\label{main-objectives}}

\begin{itemize}
\tightlist
\item
  To propose a novel environment for Reinforcement Learning algorithms, based on Cellular Automata, that could be used as an alternative benchmark instead of Atari games.
\item
  Characterize the proposed environment by solving it by state of the art methods.
\end{itemize}

\hypertarget{specific-objectives}{%
\subsection{Specific Objectives}\label{specific-objectives}}

\begin{itemize}
\tightlist
\item
  Select the a Cellular Automaton model for the environment and program it, in this case the forest fire cellular automaton.
\item
  Propose a RL task to be realized on top of the CA.
\item
  Program the RL environment, following the Open AI gym API.
\item
  Apply Dual? Q-networks with its variants.
\end{itemize}

\hypertarget{cellular-automata}{%
\chapter{Cellular Automata}\label{cellular-automata}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

Cellular Automata (sg. Cellular Automaton) are computational and mathematical systems with two essential characteristics: a discrete structure and local interaction between its parts, but its killer feature is that they are simple.

A quick \emph{Google Scholar} search for the term ``Cellular Automata'', retrieves roughly 13,000 research articles since the last year (2019). Despite not being as popular (by the same metric) as other topics, like ``Cancer'' (\textasciitilde128,000) or ``Deep Learning'' (\textasciitilde104,000), they are, arguably, still popular.

The topic of CA dates back to the 1950's spanning a history of 70 years. Since then the mathematical and practical properties of CA have been studied and its applications have been explored in different branches of science including physical and social.

Perhaps the reason behind this popularity is their simplicity. CA are composed of decentralized interactions of their individual parts (cells), these cells are usually arranged in a very regular grid and are updated following the same rules for all cells. The rules only take into account the vicinity of a given cell. From this design specifications one could naively anticipate that a very homogeneous state is reached after some iterations of the CA. But this is not always the case, surprisingly for some simple configurations and rules, complex behavior emerges. This behavior is rich enough to be used to model natural systems. The structures that arises from local interactions where not designed \emph{a priori} and their nature is capricious as they could be oscillating, chaotic, ordered, random, transient, stable. Their scale is also far from the initial size of the cell neighborhoods.

\hypertarget{main-characteristics}{%
\section{Main Characteristics}\label{main-characteristics}}

Cellular Automata are mathematical objects that are mainly characterized by (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A discrete lattice of cells:
  A n-dimensional arrangement of cells, usually 1-D, 2-D or 3-D.
\item
  Homogeneity:
  Cells are equivalent in the sense that they share an update function and a set of possible states.
\item
  Discrete states:
  Each cell is in one state from a finite set of possible states.
\item
  Local Interactions:
  Cell interactions are local, this is given by the update function being dependent on neighboring cells.
\item
  Discrete Dynamics:
  The system evolves in discrete time steps. At each step the update function is applied simultaneously (synchronously) to all cells.
\end{enumerate}

\hypertarget{mathematical-definition}{%
\section{Mathematical Definition}\label{mathematical-definition}}

The following is adapted from the book Probabilistic Cellular Automata (Louis and Nardi \protect\hyperlink{ref-louis2018probabilistic}{2018}).

Cellular Automata (CA) are dynamical systems of interconnected finite-state automata (cells). The automata evolution is through discrete time steps and it is dictated by a function dependent on a neighborhood of interacting automata.

The main mathematical aspects of a CA are:

\begin{itemize}
\item
  The network \(G\):
  A graph \(G\).
  \[ G = (V(G), E(G)) \]
  The set of vertices \(V(G)\) represents the location of the automata (cells). The set of edges \(E(G)\) describes the spatial relations between automata.
\item
  The alphabet \(S\):
  Defines the states that each automata can take. In common CA settings \(S\) is a finite set. It is also called \emph{local space} or \emph{spin space}.
\item
  The configuration space \(S^{V(G)}\):
  This is the set of all possible states of the CA. A specific configuration is denoted as:
  \[ \sigma = \{\sigma_k \in V(G)\} \]
  \(\sigma_k\) is the configuration of the automaton at position \(k\).
\item
  The neighborhoods \(V_k\):
  \[ V_k \subset  V(G) \]
  The subset of nodes that can influence or interact with the automaton at \(k \in V(G)\) (ordinarily it includes itself). A typical configuration for \(V_k\) is: \(G = \mathds{Z}^2\), and \(V_k = \{k, k \pm e_1, k \pm e_2\}\), where \((e_1, e_2)\) is the canonical basis of \(\mathds{Z}^2\), (north/south, east/west). This is known as the \emph{von Neumman neighborhood}.
\item
  The global update \(F\):
  \[ F: S^{V(G)} \rightarrow S^{V(G)} \]
  \[ (F(\sigma))_k = f_k(\sigma_{V_k}) \]
  The global update \(F\) is calculated by applying a local function \(f_k\) per automata at \(k\). In the classical setting \(f_k\) is the same for all the automata.
\end{itemize}

\hypertarget{classification}{%
\section{Classification}\label{classification}}

Wolfram from extensive simulations of 1-D CA grouped the general behavior of CA in four informally defined classes (Wolfram \protect\hyperlink{ref-wolfram2002new}{2002}). The classification is done by simulation from a variety of lattice initializations to broadly characterize the CA.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Class 1: A quick evolution towards a homogeneous global state is observed. All cells stop changing and all the randomness in the initial configuration disappears.
\item
  Class 2: The CA evolution leads to isolated patterns that could be periodic or stable.
\item
  Class 3: Pseudo-random or chaotic patterns emerge. Any stable structure is quickly destroyed by the surrounding noise.
\item
  Class 4: This is the most interesting type of behavior. Patterns that interact in a complex way emerge. These complex patterns are stable for long periods of time. Eventually the complex patterns can settle into a global state like Class 2 behavior but this can take a vast amount of time. Wolfram has conjectured that many Class 4
  CA are capable of universal computation (Wolfram \protect\hyperlink{ref-wolfram2002new}{2002}).
\end{enumerate}

This classification was inspired by the behavior observed in continuum dynamical systems. For example the homogeneous states of class 1 CA are analogous to fixed-point attracting states, or the repeating structures of class 2 CA are analogous to continuous limit cycles and class 3 chaotic patterns are analogous to strange attractors, while class 4 behavior does not have an obvious continuum analogy (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}).

Other classification schemes can be found in the literature like: based in the structure of their attractors (Kůrka \protect\hyperlink{ref-kuurka1997languages}{1997}) or by the structure of their ``Garden of Eden'' states (non-reachable global states) (Kari \protect\hyperlink{ref-kari1994reversibility}{1994}).

\hypertarget{modeling-of-complex-systems}{%
\section{Modeling of Complex Systems}\label{modeling-of-complex-systems}}

Since the consolidation of the scientific method in the XVII century two methodologies emerged for generating and evaluating scientific knowledge. Them being the ``experimental'' and the ``theoretical'' paradigms. The experimental paradigm is concerned with observing, measuring and quantifying natural phenomena in order to test an hypothesis. Experimentation also can be made in a playful manner to collect and organize data. The theoretical paradigm seeks logical and mathematical explanations of natural phenomena. Both paradigms are complementary in the sense that predictions can be made by the theoretical paradigm and be tested using the experimental one, then if the experimental findings support the predictions the theory is kept otherwise is rejected. In other words theory can be supported or falsified through experimentation.

A third scientific paradigm recently appeared, namely the ``computational'' paradigm. In this approach the study of nature is done through computer simulations. The computational paradigm works in partnership with the ``experimental'' and ``theoretical'' ones, so where observed phenomena are not easily tractable by analytical descriptions or direct experimentation is not allowed, computational simulation still permits further inquiry. Still when possible the outputs from the computations can be validated against experimental data and predictions from the theory, thus establishing helpful feedback between paradigms. The invention of the digital computer enabled the numerical solution of analytical models by means of discretization of quantities. Finally the computational paradigm can sometimes be used as a shortcut to the theoretical or experimental paradigms, for example if the problem at hand is well characterized, data obtained from a simulation could be employed as a proxy for real world data or by the contrary if the studied phenomena is poorly understood a first computational approach could be performed.

The theoretical and computational paradigms force us to formally disclose our assumptions in the form of variables, processes and relationships among them, thus forming what is known as an abstract model or simply a model. Mathematical and computational models can be grouped according on how \emph{state}, \emph{space} and \emph{time} variables are abstracted into the model (Hoekstra, Kroc, and Sloot \protect\hyperlink{ref-hoekstra2010simulating}{2010}).

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:models} How different models handle \emph{state}, \emph{space} and \emph{time}. \emph{C} stands for continuous and \emph{D} for discrete. The discrete nature of CA is highlighted.
Table taken from the book ``Simulating complex systems by cellular automata'' (Hoekstra, Kroc, and Sloot \protect\hyperlink{ref-hoekstra2010simulating}{2010}).}\tabularnewline
\toprule
Type of model & State & Space & Time\tabularnewline
\midrule
\endfirsthead
\toprule
Type of model & State & Space & Time\tabularnewline
\midrule
\endhead
Partial differential equations (PDEs) & C & C & C\tabularnewline
Integro-difference equations & C & C & D\tabularnewline
Coupled ordinary differential equations (ODEs) & C & D & C\tabularnewline
Interacting particle systems & D & D & C\tabularnewline
Coupled map lattices (CMLs) & C & D & D\tabularnewline
Systems of difference equations & C & D & D\tabularnewline
Lattice Boltzmann equations (LBEs) & C & D & D\tabularnewline
\textbf{Cellular Automata (CA)} & \textbf{D} & \textbf{D} & \textbf{D}\tabularnewline
Lattice gas automata (LGAs) & D & D & D\tabularnewline
\bottomrule
\end{longtable}

Complex systems is a broadly defined term to encompass dynamical systems with more than a few interacting parts commonly in a non-linear way, in simple terms systems that have emergent properties from individual interactions. This kind of systems are common in the the natural and social sciences. One of the classical examples is the formation of ant colonies and the organization that comes with it (Hölldobler, Wilson, and others \protect\hyperlink{ref-holldobler1994journey}{1994}). Each ant is sensing external stimuli and acting upon them, the cumulative reactions of all the ants culminates in the building of the ant-hill, feeding it, defending it and attacking other ant colonies. Everything from following from 20 to 40 responses to a particular stimuli.

As seen by the ant-colony example, a correctly chosen set of interacting rules for a group of identical generic entities can create self-organization and/or emergent behavior (Bak \protect\hyperlink{ref-bak2013nature}{2013}). However a general algorithm to find a correct set of local rules to produce a target global behavior is not know (Hoekstra, Kroc, and Sloot \protect\hyperlink{ref-hoekstra2010simulating}{2010}). Regardless going in the opposite way is as easy as running a simulation using a proposed set of rules and checking if the yield the target behavior.
In summary the question, What set of rules yields this behavior? Is extremely difficult, yet asking, Does this set of particular rules yields this behavior? Is rather easy.

In CA the same dichotomy arises. Going from local rules to global behavior (local to global mapping) is as easy as to just perform the computations defined by the CA but going in the other direction (global mapping to local) is extremely difficult. This issue is known as the ``inverse problem''. Regardless of its difficulty numerous attempts have been tried, with limited success. A common approach is the usage of optimization techniques like evolutionary algorithms or simulated annealing to find rules driving the system to desired attractor basins (Ganguly et al. \protect\hyperlink{ref-ganguly2003survey}{2003}).

The semantics of CA made them readily available to model complex systems. In fact Ilachinski mentions that \emph{``CA are, fundamentally the simplest mathematical representations of a much broader class of complex systems.''} (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}). The modeling of a complex system using CA often proceeds in a bottom-up manner. Initially essential properties of the interacting parts are abstracted and then codified into the updating rules of CA cells. Secondly the simulation is run in order to learn the \emph{mesoscopic laws} that emerge from the individual interactions. With domain knowledge this process could be iterated, first proposing essential rules and see if they produce reasonable emergent behavior and then improving the rules from this feedback. Finally the system could be enlarged to a gigantic simulation (mainly in space) to get the \emph{macroscopic} final behavior.

However Toffoli points out that this is not the best allocation of computational budget and recommends to use the learned \emph{mesoscopic laws} as input for higher-level analytical or numerical models (Hoekstra, Kroc, and Sloot \protect\hyperlink{ref-hoekstra2010simulating}{2010}). To give an example he imagines a CA that predicts the formation of water droplets from simple interactions of particles. Then if the computational resources are available the model could be escalated millions and millions of times to model fog, clouds, all the way up to global weather. However scaling in this way is not really necessary as once the bulk properties of a water droplet have been found they could easily be feed as numerical parameters of a higher-level model (e.g.~differential equation), so in the end the CA had help us to get something like droplets per cubic meters or temperature an so forth. In Toffoli words \emph{``A successful CA model is the seed of its own demise!''}, nonetheless at the end of the day the CA had help us taming the complex system and clearly expressing the essential microscopic dynamics of the system.

\hypertarget{computing}{%
\section{Computing}\label{computing}}

An analogy between CA and conventional computers can be made. The initial configuration of a CA could be though as input data to be computed over by the CA rules, producing results several time steps ahead and displayed on whatever configuration reached by the lattice.

This analogy is not coincidence at all and it is further exposed by the history of CA. In the early 1950's von Neumann was trying to build a machine that not only should be self-replicating but also capable of universal computability. Von Neumann's endeavors were successful and produced the first two-dimensional automaton formally shown to be Turing-complete (Von Neumann, Burks, and others \protect\hyperlink{ref-von1966theory}{1966}). Twenty years later John Conway's ``Game of Life'' was introduced and later was also found to be computationally universal (Elwin, Conway, and Guy \protect\hyperlink{ref-elwin1982winning}{1982})(Poundstone \protect\hyperlink{ref-poundstone2013recursive}{2013}). More recently 1-D CA ``Rule 110'' has been proved to be universal and is one of the simplest known systems with such property (Cook \protect\hyperlink{ref-cook2004universality}{2004}).

The usual strategy to prove that a given CA is universal is to show its equivalence with other systems known to be universal. Other strategy is to directly build on the lattice all the primitive elements of computing, namely \emph{storage} (memory), \emph{transmission} (internal clock and wires) and \emph{processing} (AND, OR and NOT gates) (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}). Once a given system supports these computational primitives building an universal machine becomes a clerical work of assembling modules. The ``Game of Life'' is proven to be universal in this fashion.

On the other hand possessing the same power as a conventional digital computer plays an important role on our mathematical ability to make predictions on the behavior of CA, because all universal computers require resources in the same order of magnitude to process a particular algorithm, thus in general a computational shortcut to the simulation of any universal CA does not exist (Toffoli \protect\hyperlink{ref-toffoli1977cellular}{1977}). This implies that even if an analytical expression for exactly capturing the evolution of a universal CA is obtained, evaluating such expression would take asymptotically the same time as just running the CA and observing its own evolution. Thus remarkably the most efficient way to characterize a universal CA is through its own simulation (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}).

Furthermore locality being one of the main ingredients of CA imposes an almost independent update on each cell that is only influenced by its neighbors. As the execution of the program by the CA is being carried out individually by its cells the computations are being executed in a fully parallel manner. Consequently simulations on CA allow for efficient parallel implementations of any real world system that can be codified into the CA formalism. For example CA based machines CAMs (CA Machines) have been proposed by Toffoli and others (Toffoli \protect\hyperlink{ref-toffoli1984cam}{1984}). A hardware implementation of a CAM was developed at MIT (Margolus \protect\hyperlink{ref-margolus1995cam}{1995}) that for the modeling of complex systems it could achieve a performance of several orders of magnitude higher that a traditional computer at a comparable cost.

\hypertarget{generalized-cellular-automata}{%
\subsection{Generalized Cellular Automata}\label{generalized-cellular-automata}}

Generalizations to the classical attributes of CA can be conceived (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}) enabling extensions like:

\begin{itemize}
\item
  Asynchronous CA:
  Allows asynchronous updating of the CA.
\item
  Coupled-map Lattices:
  Allows real valued cell states. These systems are simpler than partial differential equations but more complex that standard CA.
\item
  Probabilistic CA:
  The rules are allowed to be stochastic, assigning probabilities to cell state transitions.
\item
  Non-homogeneous CA:
  Updating functions are allowed to vary from cell to cell. A simple example is a CA with two rules distributed randomly throughout the lattice. On the other extreme case, simulations have been performed with random assignment of all Boolean functions with small number of inputs (Kauffman \protect\hyperlink{ref-kauffman1984emergent}{1984}).
\item
  Mobile CA:
  In this model some cells can move through the lattice. The mobile parts of the CA can be thought as robots or agents and their movement is dictated from an internal state that reflects the features of the local environment.
\item
  Structurally Dynamic CA:
  Considers the possibility of evolving cell arrangement. In standard CA the lattice is only a substrate for the ongoing computation, but what happens when this passivity is removed.
\end{itemize}

\hypertarget{history}{%
\section{History}\label{history}}

Precursor ideas about Cellular Automata (CA) can be traced back to 1946 cybernetics models of excitable media of Wiener and Rosenbluth (Weiner and Rosenblunth \protect\hyperlink{ref-weiner1946mathematical}{1946}), however their usual agreed upon inception was when in 1948 John von Neumann following a suggestion from mathematician Stanislaw Ulam introduced CA to study self replicating systems, particularly biological ones (Von Neumann and others \protect\hyperlink{ref-von1951general}{1951})(Von Neumann, Burks, and others \protect\hyperlink{ref-von1966theory}{1966}).

Von Neumann's basic idea was to build a lattice in \(\mathds{Z}^2\) capable of copying itself, to another location in \(\mathds{Z}^2\). The solution, in spite of being elaborate and involving 29 different cell states, was modular and intuitive. Since then more constructions capable of the same feat have been found with a lesser number of states (Codd \protect\hyperlink{ref-codd1968cellular}{1968}).

In the 1960's theoretical studies of CA were made, especially as instances of dynamical systems and their relation to the field of symbolic dynamics. A notable result from the epoch is the Curtis-Hedlund-Lyndon theorem (Hedlund \protect\hyperlink{ref-hedlund1969endomorphisms}{1969}), which characterizes translation-invariant CA transformations.

In 1969 Konrad Zuse published the book \emph{Calculating Space} (Zuse \protect\hyperlink{ref-zuse1970calculating}{1970}) with the thesis that the universe is fundamentally discrete as a result of the computations of a CA-like machinery. Likewise during 1960's computer scientist Alvy Ray Smith demonstrated that 1-D CA are capable of universal computation and showed equivalences between Moore and von Neumann neighborhoods, reducing the first to the second (Smith III \protect\hyperlink{ref-smith1971simple}{1971}).

A key moment came with the invention of 2-D CA Game of Life. Pure mathematician J.H. Conway created ``Life'' as a solitaire and simulation type game. To play ``Life'' a checkerboard was needed, then counters or chips were put on top of some squares. This represented an initial alive population of organisms and the initial configuration would evolve following reproduction and dying rules. The rules were tweaked by Conway to produce unpredictable and mesmerizing patterns. The game was made popular when was published as recreational mathematics by Martin Gardner in 1970 (Gardner \protect\hyperlink{ref-gardner1970mathematical}{1970}). Despite its name and interesting properties ``Life'' has little biological meaning and should be only interpreted as a metaphor (Ermentrout and Edelstein-Keshet \protect\hyperlink{ref-ermentrout1993cellular}{1993}).

During the 80s the notoriety of CA was boosted to the current status as CA became quintessential examples of complex systems. The focus of research was shifted towards CA as modeling tools. Is in this decade that the first CA conference was held at MIT (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}) and that a seminal review article of Stephen Wolfram was published (Wolfram \protect\hyperlink{ref-wolfram1983statistical}{1983}).

Since then applications have been coming in a variety of domains. In the biological sciences models of excitable media, developmental biology, ecology, shell pattern formation and immunology, to name a few, have been proposed (Ermentrout and Edelstein-Keshet \protect\hyperlink{ref-ermentrout1993cellular}{1993}). CA can be applied in image processing for noise removal and border detection (Popovici and Popovici \protect\hyperlink{ref-popovici2002cellular}{2002}). For physical systems fluid and gas dynamics are well suited for CA modeling (Margolus \protect\hyperlink{ref-margolus1984physics}{1984}). Also they have been proposed as a discrete approach to expressing physical laws (Vichniac \protect\hyperlink{ref-vichniac1984simulating}{1984}).

\begin{longtable}[]{@{}lll@{}}
\caption{Key events in the history of Cellular Automata. Table taken from the book Cellular Automata A Discrete Universe (Ilachinski \protect\hyperlink{ref-ilachinski2001cellular}{2001}).}\tabularnewline
\toprule
Year & Researcher & Discovery\tabularnewline
\midrule
\endfirsthead
\toprule
Year & Researcher & Discovery\tabularnewline
\midrule
\endhead
1936 & Turing & Formalized the concept of computability, universal Turing machine.\tabularnewline
1948 & von Neumann & Introduced self-reproducing automata.\tabularnewline
1950 & Ulam & Insisted on the need of more realistic models for the behavior of complex extended systems.\tabularnewline
1966 & Burks & Extended von Neumann's work.\tabularnewline
1967 & von Bertalanffy, et al & Applied System Theory to human systems.\tabularnewline
1969 & Zuse & Introduced the concept of ``computing spaces''.\tabularnewline
1970 & Conway & Introduced the CA ``Game of Life''.\tabularnewline
1977 & Toffoli & Applied CA to modeling physical laws.\tabularnewline
1983 & Wolfram & Authored a seminal review article about CA.\tabularnewline
1984 & Cowan, et al & The Santa Fe Institute is founded for interdisciplinary research of complex systems.\tabularnewline
1987 & Toffoli, Wolfram & First CA conference held at MIT.\tabularnewline
1992 & Varela, et al & First European conference on artificial life.\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{forest-fire-models}{%
\section{Forest Fire Models}\label{forest-fire-models}}

Forest fire models are a type of Probabilistic Cellular Automata (PCA). They try to capture the dynamics and general patterns of tree clusters that emerge from an evolving forest subject to perturbations.

They trace their origins to statistical physics and are closely related with percolation phenomena and dissipative structures. However they have been proved a valuable tool for ecological and natural hazard sciences as simple but powerful modeling tools (Zinck, Johst, and Grimm \protect\hyperlink{ref-zinck2010wildfire}{2010}).

Forest fire models help to tackle questions like: Will the tree population eventually dies out?, What is the general shape of tree clusters?, What is the shape of the boundary between the forest and the fire?

At first glance forest fire models seem similar to epidemiological cellular automata models though they place emphasis on finite population and the persistence of a pathology over time in contrast to the infinite forest population and the emphasis on the spatial extension of the fire.

They broadly have the following characteristics (Louis and Nardi \protect\hyperlink{ref-louis2018probabilistic}{2018}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cells of at least three types:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Non-burning tree
\item
  Burning tree
\item
  No tree (empty)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A rule for fire initiation:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  A starting configuration with fire cells, usually randomly chosen fire positions.
\item
  Accident simulation, like with a small probability self-ignition of a tree cell.
\item
  Space-time distributed ignition instances (e.g.~Poisson distributed).
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  A rule for fire propagation. It involves a stochastic rule for fire spreading between neighborhoods that can be based on actual terrain conditions.
\end{enumerate}

\hypertarget{the-drossel-and-schwabl-forest-fire-model}{%
\section{The Drossel and Schwabl forest fire model}\label{the-drossel-and-schwabl-forest-fire-model}}

The forest fire model that will be used through this document is the Drossel and Schwabl model (DSM) (Drossel and Schwabl \protect\hyperlink{ref-drossel1992self}{1992}).

DSM was born from research on statistical physics about phase transitions and self-organized criticality (Bak, Chen, and Tang \protect\hyperlink{ref-bak1990forest}{1990})(Drossel and Schwabl \protect\hyperlink{ref-drossel1992self}{1992}). For this reason the CA was not intended as a modeling tool for real wildfires and was only a metaphor.

Nevertheless data from real wildfires was compared against DSM predictions with the, no so surprising, observation that the model did not perfectly match real world datasets, as it was build with the only concern of generating fire sizes following a power law. DSM was overestimating the frequency of large fires (Millington, Perry, and Malamud \protect\hyperlink{ref-millington2006models}{2006}). Even though its origins and pitfalls DMS is still valuable, as it has a strong advantage against other wildfire models due to its simplicity and analytical tractability (Zinck, Johst, and Grimm \protect\hyperlink{ref-zinck2010wildfire}{2010}). Likewise it provides a set of starting assumptions that can be augmented to the required complexity along with the usually seen trade-off between increasing a model's predictive capabilities and its generalizing power.

Consequently success have been achieved using this simple model, for example fire shape patterns have been obtained that closely resemble actual wildfires (Zinck and Grimm \protect\hyperlink{ref-zinck2008more}{2008})(Zinck, Johst, and Grimm \protect\hyperlink{ref-zinck2010wildfire}{2010}).

The Drossel and Schwabl model consist of a lattice in \(\mathds{Z}^2\) populated with three type of cells: \(0\) (no tree), \(1\) (burning tree), and \(2\) (non-burning tree). All cells are synchronously updated according to the following rules:
For each state \(\sigma_k(n)\) at site \(k\) and time step \(n\).

\begin{itemize}
\item
  A burning tree is consumed at next time step:
  \[\sigma_k(n) = 1 \mapsto  \sigma_k(n) = 0 \textrm{\quad With probability}\ 1\]
\item
  A new tree grows from an empty position \(k\), dictated by parameter \(p \in [0,1]:\)
  \[\sigma_k(n) = 0 \mapsto  \sigma_k(n) = 2 \textrm{\quad With probability}\ p\]
\item
  The fire is propagated through the vicinity or a lightning event occurs, which ignites a tree and is tuned by \(f \in [0,1]:\)
  \[\sigma_k(n) = 2 \mapsto  \sigma_k(n) = 1\]
  \[\textrm{With probability} \begin{cases}
  1, & \textrm{if at least one neighboring tree is burning}\\
  f, & \textrm{if no neighboring tree is burning}
  \end{cases}\]
\end{itemize}

\hypertarget{reinforcement}{%
\chapter{Reinforcement}\label{reinforcement}}

\hypertarget{learning}{%
\section{Learning}\label{learning}}

Machine Learning
Machine Learning is a subfield of Computer Science and Artificial Intelligence (AI). It aims at creating entities capable of learning from examples. What distinguishes it from other AI approaches is the special emphasis on avoiding explicit programming for the task at hand, instead relying only on examples (data) to solve it and from there generalizing to previously unseen cases. So at the heart of this approach lies data.
In the classical machine learning setting the algorithm is provided with a set of questions and answers. Then after a period of computations over the pairs questions-answers, the algorithm is presented with new questions, some of them never seen before, that must be answered well enough.
The formalization of this setting leads to an approach known as Supervised Learning, where the questions-answers pairs are codified into mathematical objects, usually numeric vectors for questions and real numbers or categories for answers and the proposed solution comes in the form of a function that maps questions to answers. The name supervised comes from the fact that the algorithm is provided with the answers to the questions, so in a figurative way it is being supervised by a teacher.
Deviation from this classical setting leads to the other broad categories of machine learning. Unsupervised Learning algorithms are provided with just data (questions and not answers) and aim to uncover some structure in such data. Semisupervised Learning is halfway between Unsupervised and Supervised methods as only some answers are given, thus the algorithm must first find some structure on the questions (Unsupervised) to extend the answers to similar questions and then perform Supervised Learning. Finally, Reinforcement Learning algorithms get data and answers, but answers have only a grade on how favorable they are. The data and grades are obtained through interaction with an environment and the task here is to find answers that maximize the obtained grades.

\hypertarget{deep}{%
\section{Deep}\label{deep}}

Deep Learning
NeuNets for the win.

\hypertarget{reinforcement-1}{%
\section{Reinforcement}\label{reinforcement-1}}

Reinforcement Learning
The contents of this section have mostly been taken from Sutton and Barto's Introduction to Reinforcement Learning book (Sutton and Barto, 2017).
Reinforcement Learning (RL) aims to develop algorithms that can satisfactorily inform an agent which decisions to make in order to achieve a goal. The world in which the agent acts is called the environment. The decisions made by the agent affects the environment and hopefully drives it closer to the goal. A signal of how well the agent is performing is received at each decision step. The signal is called reward and it is an abstraction to represent great or poor sequences of actions. Plenty of reward means a successful agent closer to its objective.
The Reinforcement Learning Problem could be formalized with Markov Decision Processes (MDPs). The MDP framework consists of an interaction between an agent and an environment. The agent takes actions and the environment responds with observations and a reward signal, this process is repeated until termination or forever.

So at each time step \[t=0,1,2,3,...,T\] the agent using the information of state \[S_t \in S\] of the environment must choose an action \[A_t \in A(S_t)\], then in the next time step \[t+1\] the environment transits to a new state \[S_{t+1} \in S\] and returns a reward \[R \in R \subset \mathds{R}\]. The dynamics between the agent and environment produces a trajectory of states, actions and rewards indexed by time.
\[ S_0, A_0, R_1, S_1, A_1, R_2, S_2, A_2, R_3, ...\]

Of special importance is the case of a finite MDP, in which the cardinality of states, actions and rewards (\[S \], \[A\] and \[R\]) is finite.
In a finite MDP the random variables \[S_t\], \[R_t\] have a well defined discrete probability distribution that depends only on the previous action \[A_t-1\] and state \[S_t-1\]. This is known as the Markov property:
\[ p(s’, r | s, a) = Pr{S_t=s’, R_t=r | S_t-1=s, A_t-1=a} \]
To summarize a MDP is a tuple of \[S, A, P, y\].

\hypertarget{results-and-disscusion}{%
\chapter{Results and Disscusion}\label{results-and-disscusion}}

The idea and contributions of the dissertation.

Cellular Automata are discrete dynamical systems, that are well suited for the modelling of real world phenomens, particularly those who present characteristics of complex systems, such as emergent behaviour, chaotic behauvior, local behaviour, simple interactions but many actors.
Nonetheless Cellular Automata field is rich with theory and any contribution to \ldots{}
In this work we have used the forest fire automata as an environment and he have defined a \ldots{}

We use state of the art deep reinforcement learning (DRL) algorithms to control the dynamics of
cellular automata (CA) models. We assume there is an agent that can interact with the CA model by
changing the state of one or more cells in the CA during each time step. The set of actions the agent
can take vary with each specific CA model. For instance, in a CA that models the spread of fire, we
model the agent as a helicopter flying over the CA that on each step can move to an adjacent cell and
put out the fire of the cell in its current location. The goal of the agent is to minimize the spread of
fire during the simulation. Our results show that DRL algorithms can control important aspects of
CAs that model the behavior of real complex systems. On the other hand, this work shows that many
CA models can be used as benchmarks for DRL algorithms that are closer to practical applications
than many current benchmarks based on video games.

\hypertarget{forest-fire-implementation}{%
\section{Forest Fire Implementation}\label{forest-fire-implementation}}

\hypertarget{deep-q-networks-implementation}{%
\section{Deep Q-Networks Implementation}\label{deep-q-networks-implementation}}

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{training-diagrams}{%
\subsection{Training Diagrams}\label{training-diagrams}}

\hypertarget{comparative-table}{%
\subsection{Comparative Table}\label{comparative-table}}

\hypertarget{disscusion}{%
\section{Disscusion}\label{disscusion}}

\hypertarget{unsupervised}{%
\subsection{Unsupervised}\label{unsupervised}}

\hypertarget{conclusion}{%
\chapter{Conclusion}\label{conclusion}}

We have finished a nice book.

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-bak2013nature}{}%
Bak, Per. 2013. \emph{How Nature Works: The Science of Self-Organized Criticality}. Springer Science \& Business Media.

\leavevmode\hypertarget{ref-bak1990forest}{}%
Bak, Per, Kan Chen, and Chao Tang. 1990. ``A Forest-Fire Model and Some Thoughts on Turbulence.'' \emph{Physics Letters A} 147 (5-6): 297--300.

\leavevmode\hypertarget{ref-codd1968cellular}{}%
Codd, EF. 1968. ``Cellular Automata, Academic Press.'' \emph{New York}.

\leavevmode\hypertarget{ref-cook2004universality}{}%
Cook, Matthew. 2004. ``Universality in Elementary Cellular Automata.'' \emph{Complex Systems} 15 (1): 1--40.

\leavevmode\hypertarget{ref-drossel1992self}{}%
Drossel, Barbara, and Franz Schwabl. 1992. ``Self-Organized Critical Forest-Fire Model.'' \emph{Physical Review Letters} 69 (11): 1629.

\leavevmode\hypertarget{ref-elwin1982winning}{}%
Elwin, R Berkelamp, John H Conway, and Richard K Guy. 1982. ``Winning Ways for Your Mathematical Plays.'' Academic Press.

\leavevmode\hypertarget{ref-ermentrout1993cellular}{}%
Ermentrout, G Bard, and Leah Edelstein-Keshet. 1993. ``Cellular Automata Approaches to Biological Modeling.'' \emph{Journal of Theoretical Biology} 160 (1): 97--133.

\leavevmode\hypertarget{ref-ganguly2003survey}{}%
Ganguly, Niloy, Biplab K Sikdar, Andreas Deutsch, Geoffrey Canright, and P Pal Chaudhuri. 2003. ``A Survey on Cellular Automata.''

\leavevmode\hypertarget{ref-gardner1970mathematical}{}%
Gardner, Martin. 1970. ``Mathematical Games.'' \emph{Scientific American} 222 (6): 132--40.

\leavevmode\hypertarget{ref-hedlund1969endomorphisms}{}%
Hedlund, Gustav A. 1969. ``Endomorphisms and Automorphisms of the Shift Dynamical System.'' \emph{Mathematical Systems Theory} 3 (4): 320--75.

\leavevmode\hypertarget{ref-hoekstra2010simulating}{}%
Hoekstra, Alfons G, Jiri Kroc, and Peter MA Sloot. 2010. \emph{Simulating Complex Systems by Cellular Automata}. Springer.

\leavevmode\hypertarget{ref-holldobler1994journey}{}%
Hölldobler, Bert, Edward O Wilson, and others. 1994. \emph{Journey to the Ants: A Story of Scientific Exploration.} Harvard University Press.

\leavevmode\hypertarget{ref-ilachinski2001cellular}{}%
Ilachinski, Andrew. 2001. \emph{Cellular Automata: A Discrete Universe}. World Scientific Publishing Company.

\leavevmode\hypertarget{ref-kari1994reversibility}{}%
Kari, Jarkko. 1994. ``Reversibility and Surjectivity Problems of Cellular Automata.'' \emph{Journal of Computer and System Sciences} 48 (1): 149--82.

\leavevmode\hypertarget{ref-kauffman1984emergent}{}%
Kauffman, Stuart A. 1984. ``Emergent Properties in Random Complex Automata.'' \emph{Physica D: Nonlinear Phenomena} 10 (1-2): 145--56.

\leavevmode\hypertarget{ref-kuurka1997languages}{}%
Kůrka, Petr. 1997. ``Languages, Equicontinuity and Attractors in Cellular Automata.'' \emph{Ergodic Theory and Dynamical Systems} 17 (2): 417--33.

\leavevmode\hypertarget{ref-louis2018probabilistic}{}%
Louis, Pierre-Yves, and Francesca R Nardi. 2018. \emph{Probabilistic Cellular Automata}. Springer.

\leavevmode\hypertarget{ref-margolus1984physics}{}%
Margolus, Norman. 1984. ``Physics-Like Models of Computation.'' \emph{Physica D: Nonlinear Phenomena} 10 (1-2): 81--95.

\leavevmode\hypertarget{ref-margolus1995cam}{}%
---------. 1995. ``CAM-8: A Computer Architecture Based on Cellular Automata.'' \emph{arXiv Preprint Comp-Gas/9509001}.

\leavevmode\hypertarget{ref-millington2006models}{}%
Millington, James DA, George LW Perry, and Bruce D Malamud. 2006. ``Models, Data and Mechanisms: Quantifying Wildfire Regimes.'' \emph{Geological Society, London, Special Publications} 261 (1): 155--67.

\leavevmode\hypertarget{ref-popovici2002cellular}{}%
Popovici, Adriana, and Dan Popovici. 2002. ``Cellular Automata in Image Processing.'' In \emph{Fifteenth International Symposium on Mathematical Theory of Networks and Systems}, 1:1--6. Citeseer.

\leavevmode\hypertarget{ref-poundstone2013recursive}{}%
Poundstone, William. 2013. \emph{The Recursive Universe: Cosmic Complexity and the Limits of Scientific Knowledge}. Courier Corporation.

\leavevmode\hypertarget{ref-smith1971simple}{}%
Smith III, Alvy Ray. 1971. ``Simple Computation-Universal Cellular Spaces.'' \emph{Journal of the ACM (JACM)} 18 (3): 339--53.

\leavevmode\hypertarget{ref-toffoli1977cellular}{}%
Toffoli, Tommaso. 1977. ``Cellular Automata Machines.''

\leavevmode\hypertarget{ref-toffoli1984cam}{}%
---------. 1984. ``CAM: A High-Performance Cellular-Automaton Machine.'' \emph{Physica D: Nonlinear Phenomena} 10 (1-2): 195--204.

\leavevmode\hypertarget{ref-vichniac1984simulating}{}%
Vichniac, Gérard Y. 1984. ``Simulating Physics with Cellular Automata.'' \emph{Physica D: Nonlinear Phenomena} 10 (1-2): 96--116.

\leavevmode\hypertarget{ref-von1966theory}{}%
Von Neumann, John, Arthur W Burks, and others. 1966. ``Theory of Self-Reproducing Automata.'' \emph{IEEE Transactions on Neural Networks} 5 (1): 3--14.

\leavevmode\hypertarget{ref-von1951general}{}%
Von Neumann, John, and others. 1951. ``The General and Logical Theory of Automata.'' \emph{1951}, 1--41.

\leavevmode\hypertarget{ref-weiner1946mathematical}{}%
Weiner, N, and A Rosenblunth. 1946. ``The Mathematical Formulation of the Problem of Conduction of Impulses in a Network of Connected Excitable Elements Specifically in Cardiac Muscle.''

\leavevmode\hypertarget{ref-wolfram1983statistical}{}%
Wolfram, Stephen. 1983. ``Statistical Mechanics of Cellular Automata.'' \emph{Reviews of Modern Physics} 55 (3): 601.

\leavevmode\hypertarget{ref-wolfram2002new}{}%
---------. 2002. \emph{A New Kind of Science}. Vol. 5. Wolfram media Champaign, IL.

\leavevmode\hypertarget{ref-zinck2008more}{}%
Zinck, RD, and V Grimm. 2008. ``More Realistic Than Anticipated: A Classical Forest-Fire Model from Statistical Physics Captures Real Fire Shapes.'' \emph{The Open Ecology Journal} 1 (1).

\leavevmode\hypertarget{ref-zinck2010wildfire}{}%
Zinck, Richard D, Karin Johst, and Volker Grimm. 2010. ``Wildfire, Landscape Diversity and the Drossel--Schwabl Model.'' \emph{Ecological Modelling} 221 (1): 98--105.

\leavevmode\hypertarget{ref-zuse1970calculating}{}%
Zuse, Konrad. 1970. \emph{Calculating Space}. Massachusetts Institute of Technology, Project MAC Cambridge, MA.
\end{cslreferences}

\end{document}
